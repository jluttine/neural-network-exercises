\documentclass[10pt]{article}
\usepackage[english]{babel}
\usepackage[latin1]{inputenc}
\usepackage{subfigure}
\usepackage{epsfig}
\usepackage{amsmath,amssymb}
\parindent 0mm
\textwidth 16cm
\textheight 23cm
\oddsidemargin 0cm
\evensidemargin 0cm
\topmargin -10mm
\newcommand{\vect}[1]{{\bf{#1}}}
\newcommand{\svect}[1]{\boldsymbol{#1}}
\newcommand{\matr}[1]{\boldsymbol{#1}}


\begin{document}
\pagestyle{empty}
\begin{Large}
\begin{bf} 
T-61.5130 Machine Learning and Neural Networks\\ 
\end{bf}
\end{Large}
Karhunen, Hao Tele\\  
\\
\begin{large}
\begin{bf}
Exercise 10,  088888888.12.2011
\end{bf}
\end{large}
\begin{enumerate}


\item Assume a mixture of time-delayed (but not convolved) sources with known delays $D_{ij}$:
\begin{displaymath}
  x_i(t) = \sum_{j=1}^N a_{ij}s_j(t-D_{ij}),
\end{displaymath}
\begin{enumerate}
\item Show that by Fourier transform, this can be reduced to the instantaneous mixture
  model $\mathbf{X} = \mathbf{A} \mathbf{S}$.
\item From this mixing matrix $\mathbf{A}$, how do you solve the original mixing
  coefficients $a_{ij}$?
\end{enumerate}


\vspace{2mm}

\item Prove the following properties of kurtosis by using the definition of kurtosis:
  If $x_1$ and $x_2$ are independent random variables, then
  \begin{displaymath}
    kurt(x_1 + x_2) = kurt(x_1) + kurt(x_2)
  \end{displaymath}
  \begin{displaymath}
    kurt(\alpha x_1) = \alpha^4 kurt(x_1)
  \end{displaymath}
  where $\alpha$ is a scalar.
  

\vspace{2mm}

\item Consider a situation in which scalar inputs of a
one-dimensional SOM are distibuted according to the probability
distribution function $p(x)$. A stationary state
of the SOM is reached when the expected changes in the weight
values become zero:
\begin{equation*}
E[h_{j,i(x)}(x-w_j)]=0
\end{equation*}
Here $h_{j,i(x)}$ is the value of the neighborhood function for neuron $j$ in the neighborhood
of the winning neuron $i(x)$ for the input vector $x$.
What are the stationary weight values in the following cases: \begin{enumerate}
\item $h_{j,i(x)}$ is a constant for all $j$ and $i(x)$, and
\item $h_{j,i(x)}$ is the Kronecker delta function?
\end{enumerate}

\vspace{2mm}

\item It is sometimes said that the SOM algorithm preserves the topological relationships that exist in
the input space. Strictly speaking, this property can be guaranteed only for an input space of
equal or lower dimensionality than that of the neural lattice. Discuss the validity of this statement.

\vspace{2mm}

\item SOM Toolbox demos: see {\tt som\_demo3.m}

\end{enumerate}
\end{document}             % End of document.
